<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8" />
  <link rel="stylesheet" href="/style/style.css">
  <title>DL reading list</title>
</head>

<body>
	<h2 class="article-title">Deep learning articles</h2>
	<p>Reading list:</p>
	<ul>
	<li>
	<p>Hinton & Sejnowski (1983).
	<br>
	<a href="https://www.cs.toronto.edu/~fritz/absps/optimal.pdf" class="external">Optimal Perceptual Inference</a> <strong>(Boltzmann machines)</strong>.</p>
	</li>
	<li>
	<p>Rumelhart, Hinton & Williams (1986).
	<br>
	<a href="https://www.iro.umontreal.ca/~vincentp/ift3395/lectures/backprop_old.pdf" class="external">Learning representations by back-propagating errors</a> <strong>(Backpropagation)</strong>. <em>Nature</em>, Vol. 323, pp. 533–536.</p>
	</li>
	<li>
	<p>LeCun, Bottou, Bengio & Haffner (1998).
	<br>
	<a href="http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf" class="external">Gradient-based learning applied to document recognition</a> <strong>(LeNet-5)</strong>. <em>Proceedings of the IEEE</em>, Vol. 86, pp. 2278–2324.</p>
	</li>
	<li>
	<p>Bengio, Ducharme, Vincent & Janvin (2003).
	<br>
	<a href="https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf" class="external">A neural probabilistic language model</a> <a href="https://proceedings.neurips.cc/paper_files/paper/2000/file/728f206c2a01bf572b5940d7d9a8fa4c-Paper.pdf" class="external">[link 2]</a> <strong>(Bengio NPLM -- Distributed embeddings)</strong>. <em>J. Mach. Learn. Res.</em>, Vol. 3, pp. 1137–1155.</p>
	</li>
	<li>
	<p>Krizhevsky, Sutskever & Hinton (2012).
	<br>
	<a href="https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf" class="external">ImageNet Classification with Deep Convolutional Neural Networks</a> <strong>(AlexNet)</strong>. <em>In Proceedings of the Proceedings of the 25th International Conference on Neural Information Processing Systems (NIPS)</em>, Vol. 1, pp. 1097–1105.</p>
	</li>
	<li>
	<p>Kingma & Welling (2013).
	<br>
	<a href="https://arxiv.org/abs/1312.6114" class="external">Auto-Encoding Variational Bayes</a> <strong>(VAE)</strong>. <em>CoRR</em>, Vol. abs/1312.6114.</p>
	</li>
	<li>
	<p>Bahdanau, Cho & Bengio (2014).
	<br>
	<a href="https://arxiv.org/abs/1409.0473" class="external">Neural Machine Translation by Jointly Learning to Align and Translate</a> <strong>(Attention in seq2seq models)</strong>. <em>CoRR</em>, Vol. abs/1409.0473.</p>
	</li>
	<li>
	<p>Goodfellow, Pouget-Abadie, Mirza, Xu, Warde-Farley, Ozair, Courville & Bengio (2014).
	<br>
	<a href="https://arxiv.org/pdf/1406.2661" class="external">Generative adversarial nets</a> <a href="https://arxiv.org/abs/2308.16316" class="external">[Survey 1]</a> <a href="https://arxiv.org/abs/1906.01529" class="external">[Survey 2]</a> <a href="https://arxiv.org/abs/2112.12625" class="external">[Image to image]</a> <a href="https://arxiv.org/abs/2302.08641" class="external">[Transformers + GANs]</a> <strong>(GANs)</strong>. <em>In Proceedings of the Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2</em>, pp. 2672–2680.</p>
	</li>
	<li>
	<p>Kingma & Ba (2014).
	<br>
	<a href="https://arxiv.org/abs/1412.6980" class="external">Adam: A Method for Stochastic Optimization</a> <strong>(Adam)</strong>. <em>CoRR</em>, Vol. abs/1412.6980.</p>
	</li>
	<li>
	<p>Simonyan & Zisserman (2014).
	<br>
	<a href="https://arxiv.org/abs/1409.1556" class="external">Very Deep Convolutional Networks for Large-Scale Image Recognition</a> <strong>(VGG-16)</strong>. <em>CoRR</em>, Vol. abs/1409.1556.</p>
	</li>
	<li>
	<p>Sutskever, Vinyals & Le (2014).
	<br>
	<a href="https://arxiv.org/abs/1409.3215" class="external">Sequence to sequence learning with neural networks</a> <strong>(Encoder-decoder / seq2seq)</strong>. <em>In Proceedings of the Proceedings of the 28th International Conference on Neural Information Processing Systems - Volume 2</em>, pp. 3104–3112.</p>
	</li>
	<li>
	<p>Szegedy, Liu, Jia, Sermanet, Reed, Anguelov, Erhan, Vanhoucke & Rabinovich (2014).
	<br>
	<a href="https://arxiv.org/abs/1409.4842" class="external">Going deeper with convolutions</a> <strong>(Inception / GoogLeNet)</strong>. <em>2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pp. 1-9.</p>
	</li>
	<li>
	<p>Redmon, Divvala, Girshick & Farhadi (2015).
	<br>
	<a href="https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Redmon_You_Only_Look_CVPR_2016_paper.pdf" class="external">You Only Look Once: Unified, Real-Time Object Detection</a> <a href="https://arxiv.org/abs/1612.08242" class="external">[v2]</a> <a href="https://arxiv.org/abs/1804.02767" class="external">[v3]</a> <a href="https://arxiv.org/pdf/2304.00501" class="external">[v4+]</a> <strong>(YOLO algorithm)</strong>. <em>2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, pp. 779-788.</p>
	</li>
	<li>
	<p>Ronneberger (2015).
	<br>
	<a href="#" class="external">U-Net: Convolutional Networks for Biomedical Image Segmentation</a> <strong>(U-net)</strong>. <em>In Proceedings of the Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015</em>, pp. 234–241.</p>
	</li>
	<li>
	<p>Schroff, Kalenichenko & Philbin (2015).
	<br>
	<a href="https://arxiv.org/abs/1503.03832" class="external">FaceNet: A Unified Embedding for Face Recognition and Clustering</a> <strong>(FaceNet)</strong>. <em>In Proceedings of the Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>.</p>
	</li>
	<li>
	<p>Sohl-Dickstein, Weiss, Maheswaranathan & Ganguli (2015).
	<br>
	<a href="https://arxiv.org/abs/1503.03585" class="external">Deep unsupervised learning using nonequilibrium thermodynamics</a> <strong>(Early diffusion models)</strong>. <em>In Proceedings of the Proceedings of the 32nd International Conference on International Conference on Machine Learning - Volume 37</em>, pp. 2256–2265.</p>
	</li>
	<li>
	<p>He, Zhang, Ren & Sun (2016).
	<br>
	<a href="https://arxiv.org/abs/1512.03385" class="external">Deep Residual Learning for Image Recognition</a> <strong>(ResNet)</strong>. <em>In Proceedings of the 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, Vol. , pp. 770-778.</p>
	</li>
	<li>
	<p>Howard, Zhu, Chen, Kalenichenko, Wang, Weyand, Andreetto & Adam (2017).
	<br>
	<a href="https://arxiv.org/abs/1704.04861" class="external">MobileNets: Efficient Convolutional Neural Networks for Mobile Vision Applications</a> <strong>(MobileNet v1)</strong>. <em>ArXiv</em>, Vol. abs/1704.04861.</p>
	</li>
	<li>
	<p>Kaiser, Gomez, Shazeer, Vaswani, Parmar, Jones & Uszkoreit (2017).
	<br>
	<a href="https://arxiv.org/abs/1706.05137" class="external">One Model To Learn Them All</a>. <em>ArXiv</em>, Vol. abs/1706.05137.</p>
	</li>
	<li>
	<p>Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser & Polosukhin (2017).
	<br>
	<a href="https://arxiv.org/abs/1706.03762" class="external">Attention is all you need</a> <strong>(Transformers)</strong>. <em>In Proceedings of the Proceedings of the 31st International Conference on Neural Information Processing Systems</em>, pp. 6000–6010.</p>
	</li>
	<li>
	<p>Radford & Narasimhan (2018).
	<br>
	<a href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf" class="external">Improving Language Understanding by Generative Pre-Training</a> <strong>(GPT1, OpenAI / autoregressive pretraining)</strong>.</p>
	</li>
	<li>
	<p>Sandler, Howard, Zhu, Zhmoginov & Chen (2018).
	<br>
	<a href="https://arxiv.org/abs/1801.04381" class="external">MobileNetV2: Inverted Residuals and Linear Bottlenecks</a> <strong>(MobileNet v2)</strong>. <em>2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition</em>, pp. 4510-4520.</p>
	</li>
	<li>
	<p>Devlin, Chang, Lee & Toutanova (2019).
	<br>
	<a href="https://arxiv.org/abs/1810.04805" class="external">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a> <strong>(BERT / Masked Language Modeling / pretraining -> fine tuning)</strong>. <em>In Proceedings of the North American Chapter of the Association for Computational Linguistics</em>.</p>
	</li>
	<li>
	<p>Tan & Le (2019).
	<br>
	<a href="https://proceedings.mlr.press/v97/tan19a.html" class="external">EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks</a> <strong>(EfficientNet)</strong>. <em>In Proceedings of the Proceedings of the 36th International Conference on Machine Learning</em>, Vol. 97, pp. 6105–6114.</p>
	</li>
	<li>
	<p>Ho, Jain & Abbeel (2020).
	<br>
	<a href="https://arxiv.org/abs/2006.11239" class="external">Denoising Diffusion Probabilistic Models</a> <strong>(DDPM / Diffusion models / VAE)</strong>. <em>In Proceedings of the Advances in Neural Information Processing Systems</em>, Vol. 33, pp. 6840–6851.</p>
	</li>
	<li>
	<p>Bank, Koenigstein & Giryes (2021).
	<br>
	<a href="https://arxiv.org/abs/2003.05991" class="external">Autoencoders</a>.</p>
	</li>
	<li>
	<p>Michelucci (2022).
	<br>
	<a href="https://arxiv.org/abs/2201.03898" class="external">An Introduction to Autoencoders</a>.</p>
	</li>
	<li>
	<p>Behrouz, Razaviyayn, Zhong & Mirrokni (2025).
	<br>
	<a href="https://abehrouz.github.io/files/NL.pdf" class="external">Nested Learning: The Illusion of Deep Learning Architectures</a> <a href="https://arxiv.org/search/cs?searchtype=author&query=Behrouz,+A" class="external">[More papers by A. Berhouz]</a> <strong>(Nested Learning / Hope)</strong>. <em>In Proceedings of the The Thirty-ninth Annual Conference on Neural Information Processing Systems</em>.</p>
	</li>
	</ul>
</body>
</html>

